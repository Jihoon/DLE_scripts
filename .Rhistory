# load("./Saved tables/ZAF_FD_harmonized.Rda") #ZAF_FD_ICP_AllHH
# list[all_HH_c_ZA, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'ZAF', ZAF_FD_ICP_HH_adj, ZAF_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_ZA) * as.numeric(ZAF_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
# list[all_HH_c_ZA, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'ZAF', ZAF_FD_ICP_AllHH, ZAF_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_ZA) * as.numeric(ZAF_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
#
# rm(all_HH_c_BR, all_HH_c_IN, all_HH_c_ZA)
# gc()
### 2. Deriving DLE threshold [kg/cap] for Clothing (and average too)
# Derive from India data and apply the same $/kg (IND) to get kg/cap in BRA and ZAF
datapath <- "C:/Users/min/IIASA/DLE - Documents/WS3 - Documents/Trajectories/Clothing/"
weight.clothing <- read_xlsx(paste0(datapath, "Weights-IND.xlsx"), range="A1:J31") %>% select(CODE, `g/each - MIN`, `g/each - MAX`) %>%
rename(weight.min=`g/each - MIN`, weight.max=`g/each - MAX`, code=CODE)
### India
# No quantity for some items (code=372, 356, 357, 368, 375) -> Assume same avg price as 'shirts, T-shirts' (for decile1) (code=363)
price.shirt <- as.numeric(IND_clothing %>% filter(code==363) %>% mutate(price=val_tot/qty_tot) %>%
left_join(IND_HH,  by = c("id" = "hhid")) %>% filter(decile=="decile1") %>%
summarise(price.shirt=weighted.mean(price, weight, na.rm=T)))
# Get total weight by hh in gram (and val_tot too)
clothing.all <- IND_clothing %>% inner_join(weight.clothing) %>%
mutate_cond(code %in% c(372, 356, 357, 368, 375), qty_tot=val_tot/price.shirt) %>% # fill in qty for no-price items
mutate(weight.tot=qty_tot*weight.min, weight.tot.max=qty_tot*weight.max) %>%
mutate_cond(code==374, weight.tot=qty_tot) %>% # knitting wool
group_by(id) %>% summarise(val_tot=sum(val_tot, na.rm=TRUE), weight.tot=sum(weight.tot, na.rm=TRUE), weight.tot.max=sum(weight.tot.max, na.rm=TRUE)) %>%
left_join(IND_HH, by = c("id" = "hhid"))
# Get total weight by hh in gram (and val_tot too)
footwear.all <- IND_footwear %>% inner_join(weight.clothing) %>%
mutate(weight.tot=qty_tot*weight.min, weight.tot.max=qty_tot*weight.max) %>%
group_by(id) %>% summarise(val_tot=sum(val_tot, na.rm=TRUE), weight.tot=sum(weight.tot, na.rm=TRUE), weight.tot.max=sum(weight.tot.max, na.rm=TRUE)) %>%
left_join(IND_HH, by = c("id" = "hhid"))
avg.HDD.IND <- weighted.mean(IND_HH$HDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
# avg.HDD.18.IND <- weighted.mean(IND_HH$HDD.18, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
avg.CDD.IND <- weighted.mean(IND_HH$CDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE)
IND_HH.CDDHDD <- IND_HH %>%
mutate_cond(is.nan(HDD), HDD=avg.HDD.IND) %>%
# mutate_cond(is.nan(HDD.18), HDD.18=avg.HDD.18.IND) %>%
mutate_cond(is.nan(CDD), CDD=avg.CDD.IND) %>% select(id, region, HDD, CDD) #, HDD.18)
clothing.HDD <- clothing.all %>% full_join(footwear.all %>% select(id, weight.tot.f = weight.tot)) %>%
left_join(IND_HH.CDDHDD) %>%
mutate_at(vars(weight.tot, income), funs(pcap=./hh_size)) %>% mutate(HDD2 = HDD^2)
IND_HH <- selectDBdata(ID, WEIGHT, CONSUMPTION, HH_SIZE, EXPENDITURE, REGION, tables=c(paste0(svy, '_HH'))) %>%
mutate_cond(region=="Orissa", region="Odisha")
# There were duplicate rows for Tamil Nadu, which had to be removed from the CSV files directly.
hdd.IND <-
# read_csv(paste0(hdd.path, "DoT_HDD_tas_18.3India.csv")) %>%
read_csv(paste0(hdd.path, "DoT_HDD_tas_30.0India.csv")) %>%
# read_csv(paste0(hdd.path, "DoT_HDD_tas_18India.csv")) %>%
filter(var=="HDDsum" & stat=="PopWeightAv") %>%
select(-index, -var, -stat, -State) %>%
rename(region=reg, HDD=value) %>%
mutate_cond(region=="NCT of Delhi", region="Delhi")
cdd.IND <- read_csv(paste0(hdd.path, "DoT_CDD_tas_18.3India.csv")) %>% filter(var=="CDDsum" & stat=="PopWeightAv") %>%
select(-index, -var, -stat, -State) %>%
rename(region=reg, CDD=value) %>%
mutate_cond(region=="NCT of Delhi", region="Delhi")
IND_HH <- IND_HH  %>% left_join(hdd.IND) %>%
# left_join(hdd.IND.18) %>%
left_join(cdd.IND)
avg.HDD.IND <- weighted.mean(IND_HH$HDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
# avg.HDD.18.IND <- weighted.mean(IND_HH$HDD.18, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
avg.CDD.IND <- weighted.mean(IND_HH$CDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE)
IND_HH.CDDHDD <- IND_HH %>%
mutate_cond(is.nan(HDD), HDD=avg.HDD.IND) %>%
# mutate_cond(is.nan(HDD.18), HDD.18=avg.HDD.18.IND) %>%
mutate_cond(is.nan(CDD), CDD=avg.CDD.IND) %>% select(id, region, HDD, CDD) #, HDD.18)
clothing.HDD <- clothing.all %>% full_join(footwear.all %>% select(id, weight.tot.f = weight.tot)) %>%
left_join(IND_HH.CDDHDD) %>%
mutate_at(vars(weight.tot, income), funs(pcap=./hh_size)) %>% mutate(HDD2 = HDD^2)
IND_HH.CDDHDD <- IND_HH %>%
mutate_cond(is.nan(HDD), HDD=avg.HDD.IND) %>%
# mutate_cond(is.nan(HDD.18), HDD.18=avg.HDD.18.IND) %>%
mutate_cond(is.nan(CDD), CDD=avg.CDD.IND) %>% select(id, region, HDD, CDD) #, HDD.18)
outliers <- clothing.HDD %>% filter(weight.tot > 100000  | weight.tot.f > 50000) %>% select(id)
outlier_consumption <- IND_clothing %>% right_join(outliers)
clothing.HDD <- clothing.HDD %>% filter(!(id %in% outliers$id))
clothing.HDD <- clothing.all %>% full_join(footwear.all %>% select(id, weight.tot.f = weight.tot)) %>%
left_join(IND_HH.CDDHDD) %>%
mutate_at(vars(weight.tot, income), funs(pcap=./hh_size)) %>% mutate(HDD2 = HDD^2)
# # Eyeballing data
# ggplot(clothing.HDD, aes(x=HDD, y=weight.tot)) +
#   geom_point(aes(colour = decile))
# ggplot(clothing.HDD, aes(x=HDD.18, y=weight.tot)) +
#   geom_point(aes(colour = decile))
# ggplot(clothing.HDD, aes(x=HDD, y=weight.tot.f)) +
#   geom_point(aes(colour = decile))
# Detected evident outliers. Need to remove them
outliers <- clothing.HDD %>% filter(weight.tot > 100000  | weight.tot.f > 50000) %>% select(id)
outlier_consumption <- IND_clothing %>% right_join(outliers)
clothing.HDD <- clothing.HDD %>% filter(!(id %in% outliers$id))
lm.clothing <- lm(weight.tot ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
lm.clothing.18 <- lm(weight.tot ~ expenditure + HDD.18 + hh_size, clothing.HDD, weights = weight)
lm.footwear <- lm(weight.tot.f ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
summary(lm.clothing)
summary(lm.clothing.18)
lm.clothing <- lm(weight.tot ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
# lm.clothing <- lm(weight.tot ~ consumption + HDD + hh_size, clothing.HDD)
# lm.clothing.18 <- lm(weight.tot ~ expenditure + HDD.18 + hh_size, clothing.HDD, weights = weight)
lm.footwear <- lm(weight.tot.f ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
summary(lm.clothing)
# summary(lm.clothing.18)
summary(lm.footwear)
install_github("dgrtwo/broom")
library(broom)
install.packages("rlang")
install.packages("rlang")
install_github("dgrtwo/broom")
library(broom)
install.packages(c("callr", "car", "carData", "CDM", "chron", "cli", "coda", "covr", "data.table", "dbplyr", "devtools", "digest", "doParallel", "dotCall64", "dplyr", "evaluate", "expm", "fansi", "ffbase", "gamlss", "gamlss.data", "gamlss.dist", "gbm", "htmlwidgets", "igraph", "installr", "ipred", "IRdisplay", "janitor", "jomo", "kernlab", "later", "lava", "lavaan", "lme4", "magic", "magick", "maptools", "MCMCpack", "miceadds", "micemd", "microbenchmark", "mime", "mipfp", "mirt", "ModelMetrics", "nloptr", "NLP", "openssl", "pacman", "pkgconfig", "plotrix", "pls", "processx", "R.matlab", "R.utils", "R6", "raster", "Rcpp", "RcppArmadillo", "reprex", "reticulate", "robustbase", "rstudioapi", "sandwich", "scales", "snakecase", "spatstat", "spatstat.data", "spatstat.utils", "stringi", "Surrogate", "survey", "TAM", "testthat", "tidyselect", "tidytext", "tinytex", "tm", "VGAM", "webshot", "weights", "wordcloud", "XML", "xtable", "yaml", "zoo"))
library(broom)
install.packages("rlang")
library(broom)
install.packages("tidyselect)
install.packages("tidyselect")
library(broom)
source('H:/MyDocuments/IO work/DLE_scripts/Init.R', echo=TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/Init.R', echo=TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("scales")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("digest")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("later")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("mime")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("expm")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("lme4")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("chron")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("igraph")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("tm")
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("wordcloud")
install.packages("qdap", dependencies = TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("spatstat", dependencies = TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("Rcpp", dependencies = TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("Rcpp", dependency=TRUE)
install.packages("Rcpp", dependency = TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
install.packages("RcppArmadillo", dependency = TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/.Rprofile', echo=TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/Init.R', echo=TRUE)
source('H:/MyDocuments/IO work/DLE_scripts/Init.R', echo=TRUE)
#########################################
### Get EXIO FD vectors for countries ###
#########################################
# Get IND final demand from EXIO [M.EUR to M.USD]
IND_place <- which(exio_ctys=="IN")
IND_idx_fd <- seq(7*(IND_place-1)+1, 7*IND_place)   # 7 final demand columns per country
IND_idx_ex <- seq(200*(IND_place-1)+1, 200*IND_place)   # 200 EXIO comodities
IND_idx_ex.i <- seq(163*(IND_place-1)+1, 163*IND_place)   # 163 EXIO industries
IND_fd_ex <- matrix(final_demand[,IND_idx_fd[1]], nrow=200) / EXR_EUR$r  # to M.USD (2007 MER)
IND_fd_exio <- rowSums(IND_fd_ex) # Sum all HH FD across countries
IND_fd_exio_imp <- rowSums(IND_fd_ex[,-IND_place]) # Sum all HH FD across countries
# Get BRA final demand from EXIO [M.EUR to M.USD]
BRA_place <- which(exio_ctys=="BR")
BRA_idx_fd <- seq(7*(BRA_place-1)+1, 7*BRA_place)   # 7 final demand columns per country
BRA_idx_ex <- seq(200*(BRA_place-1)+1, 200*BRA_place)   # 7 final demand columns per country
# Issue: This 'final_demand' for BRA gives too small values for electricity expenditure.
# Instead I can use the column from 'BR_output.xls' file.
# BRA_fd_ex <- matrix(final_demand[,BRA_idx_fd[1]], nrow=200)
# BRA_fd_exio <- rowSums(BRA_fd_ex) # Sum all HH FD across countries
# BRA_fd_exio_imp <- rowSums(BRA_fd_ex[,-BRA_place]) # Sum all HH FD across countries
BRA_fd_ex <- read_excel("H:/MyDocuments/IO work/Valuation/BR_output.xls", sheet="usebptot", skip=14, col_names=FALSE)
# Issue: Brazil FD has zero education expediture. (reasons unknown)
# Simply replace the zero with the values found on actual BRA IO
BRA_fd_exio <- as.matrix(BRA_fd_ex[1:200,169])
BRA_fd_exio[174] <- 15600  # M Euro
BRA_fd_exio <- BRA_fd_exio / EXR_EUR$r  # to M.USD 2007
# The value 15600 is from H:\MyDocuments\IO work\Bridging\CES-COICOP\BRA IO FD comparison.xlsx
# Get ZAF final demand from EXIO [M.EUR to M.USD]
ZAF_place <- which(exio_ctys=="ZA")
ZAF_idx_fd <- seq(7*(ZAF_place-1)+1, 7*ZAF_place)   # 7 final demand columns per country
ZAF_idx_ex <- seq(200*(ZAF_place-1)+1, 200*ZAF_place)   # 200 EXIO comodities
ZAF_idx_ex.i <- seq(163*(ZAF_place-1)+1, 163*ZAF_place)   # 163 EXIO industries
ZAF_fd_ex <- matrix(final_demand[,ZAF_idx_fd[1]], nrow=200) / EXR_EUR$r  # to M.USD (2007 MER)
ZAF_fd_exio <- rowSums(ZAF_fd_ex) # Sum all HH FD across countries
#########################################
### Read in COICOP-EXIO Qual mapping  ###
#########################################
# Issue: This is to be replaced by 'bridge_ICP_EXIO_q' (currently in Map_CES_COICOP.R).
#       But bridge_COICOP_EXIO_q is used as a base for contructing bridge_ICP_EXIO_q.
#       I will move the scripts here (or call from here) once it is being used
n_sector_coicop <- 109
# Mapping <- system.file("COICOP3_EXIO_bridge.xlsx", package = "XLConnect")
# wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Uncertainty/COICOP3_EXIO_bridge.xlsx")
wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Bridging/CES-COICOP/COICOIP_EXIO_Qual_UN_Edited.xlsx")
# Qualitative mapping (0 or 1)
# bridge_COICOP_EXIO_q <- XLConnect::readWorksheet(wb, sheet="Qual_DK+FR", header=FALSE,
#                                                  startRow=3, endRow=2+n_sector_coicop, startCol=2, forceConversion=T)
bridge_COICOP_EXIO_q <- XLConnect::readWorksheet(wb, sheet="COICOIP_EXIO_Qual_UN", header=FALSE,
startRow=2, endRow=1+n_sector_coicop, startCol=1, endCol= 201, forceConversion=T)
# Compare Gibran's updated qual mapping
# wb <- XLConnect::loadWorkbook("C:/Users/min/Dropbox/HH environmental consumption/NTNU/product classification/COICOP3_EXIO_bridge.xlsx")
# bridge_ntnu <- XLConnect::readWorksheet(wb, sheet="qualitative 0_1", header=FALSE,
#                                                  startRow=3, endRow=2+n_sector_coicop, startCol=3, forceConversion=T)
# Final COICOP classification with 109 headings
COICOP_catnames2 <- XLConnect::readWorksheet(wb, sheet="COICOIP_EXIO_Qual_UN", header=FALSE, startRow=2, endRow=1+n_sector_coicop, startCol=1, endCol=1)
EX_catnames <- XLConnect::readWorksheet(wb, sheet="COICOIP_EXIO_Qual_UN", header=FALSE, startRow=1, endRow=1, startCol=2)
# Issue: This qual mapping may change depending on countries, which we need to tackle then.
#####################################################
###     Treating CES fuel sectors differently     ###
#####################################################
wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Bridging/CES-COICOP/CES_fuel_EXIO.xlsx")
bridge_fuel_EXIO_q  <- XLConnect::readWorksheet(wb, "Sheet1", header=TRUE, forceConversion=T,
startRow=2, startCol=3, endCol=202)
DLE_fuel_sector_Q  <- XLConnect::readWorksheet(wb, "Sheet2", header=TRUE, forceConversion=T,
startRow=2, startCol=3)
DLE_fuelnames_std  <- XLConnect::readWorksheet(wb, "Sheet1", header=TRUE, forceConversion=T,
startRow=2, startCol=2, endCol=2)
DLE_fuel_sector_Q[is.na(DLE_fuel_sector_Q)] <- 0
bridge_fuel_EXIO_q[is.na(bridge_fuel_EXIO_q)] <- 0
names(bridge_fuel_EXIO_q) <- EX_catnames
row.names(bridge_fuel_EXIO_q) <- DLE_fuelnames_std[,1]
names(DLE_fuelnames_std) <- "item"
############################################################
### Read final demand vector from each country's CES DB  ###
############################################################
# source("P:/ene.general/DecentLivingEnergy/Surveys/Scripts/00 Load required packages.R")
# source("P:/ene.general/DecentLivingEnergy/Surveys/Scripts/01 Load generic helper functions.R")
source("P:/ene.general/DecentLivingEnergy/Surveys/Generic function to access database.R")
# source("P:/ene.general/DecentLivingEnergy/Surveys/Scripts/Functions for building Oracle DB tables.R")
source("Read_final_demand_from_DB.R")
source("Read_direct_energy_from_DB.R")
# Read total FD for all population
# dim: n_CES_sector x 2 (or 11 for deciles)
# Comprehensive fuel sectors (union of all DBs)
DLE_fuel_types <- ConstructyFuelTypeSet() %>% arrange(fuel)
# Reading and constructing matrices
# source("Read_DLE_DB.R")
# IND
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/IND_FD.Rda")
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/IND_HH.Rda")
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/IND_AllHHConsump.Rda")
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/IND1_FUEL_Alldata.Rda") # IND_FUEL_Alldata
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/IND_FD_harmonized.Rda") # IND_FD_ICP_AllHH
# ZAF
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/ZAF_FD.Rda")
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/ZAF_HH.Rda")
load(file="H:/MyDocuments/IO work/DLE_scripts/Saved tables/ZAF_AllHHConsump.Rda")
##############################################
###     Read in ICP-EXIO Qual mapping      ###
##############################################
# This is already excuted and saved in a file.
# Don't need to run everytime.
# source("Generate_base_ICP-EXIO_mapping.R")
n_sector_icp <- 151  # Num of ICP sectors
n_sector_icp_fuel <- n_sector_icp + dim(DLE_fuelnames_std)[1]
##############################################
###     Read in ICP-EXIO Qual mapping      ###
##############################################
# This matrix is modified externally manually based on the resulting csv from running Generate_base_ICP-EXIO_mapping.R
# to fine-allocate mostly for food-subsectors.
# The result is in H:\MyDocuments\IO work\Bridging\CES-COICOP\ICP_EXIO_Qual_Edited.xlsx
# Manually changed cells are colored in green in the xlsx file.
# Two types of manual changes
#   1. ICP item disaggregation info further details (meat -> poultry)
#   2. Some positive EXIO FD values do not match to any ICP sectors. (e.g. stone from EXIO mapped to household maintenance in ICP)
#     => can be checked by cbind(names(qual_map)[colConst_init!=0 & colSums(qual_map_init)==0], colConst_init[colConst_init!=0 & colSums(qual_map_init)==0])
# wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Bridging/CES-COICOP/ICP_EXIO_Qual_Edited.xlsx")
# bridge_ICP_EXIO_q  <- XLConnect::readWorksheet(wb, "ICP_EXIO_Q_nochange", header=TRUE, forceConversion=T, endRow=152, endCol=201)
wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Bridging/CES-COICOP/ICP_EXIO_Qual_UN_Edited.xlsx")
bridge_ICP_EXIO_q  <- XLConnect::readWorksheet(wb, "ICP_EXIO_Qual_UN2", header=TRUE,
forceConversion=T, endCol=201)
ICP_catnames <- bridge_ICP_EXIO_q[,1]
#####################################################
### Read in (CES-Pseudo COICOP) mappings from WB  ###
#####################################################
### Read in ICP heading number following NTNU 109 mapping (not 100%, some ICP headings are aggregated) ###
Mapping <- system.file("ICP_SEQ.xlsx", package = "XLConnect")
wb <- XLConnect::loadWorkbook("H:/MyDocuments/IO work/Bridging/CES-COICOP/Worldbank/ICP_SEQ.xls")
# I added 'Sheet2' and fixed some mis-categorizations for my needs.
icp_seq <- XLConnect::readWorksheet(wb, sheet="Sheet2", header=TRUE, startRow=2, startCol=1, endCol=1, forceConversion=T)
icp_cat <- XLConnect::readWorksheet(wb, sheet="Sheet2", header=FALSE, startRow=3, startCol=3, endCol=4, forceConversion=T)
NTNU <- XLConnect::readWorksheet(wb, sheet="Sheet2", header=TRUE, startRow=2, startCol=7, endCol=8, forceConversion=T)
icp_ntnu <-cbind(icp_seq, icp_cat, NTNU)
names(icp_ntnu)[2:3] <- c("COICOP1","COICOP2")
names(icp_ntnu)[5] <- "ICP_Heading"
source("rIPFP - Process_WB.R")  # Read in the function 'processWBscript' and resulting mtxs for 4 countries
# Issue: I still need to match with our CES DB and final NTNU 109 classification
#        How to combine fuel consumption and other (food etc)
#       -> We decided to follow ICP headings from the WB and bridge this ICP classification to EXIO.
##############################################
###       Generate CES-ICP mapping         ###
##############################################
# Read in CES code tables, fix some mis-mappings from WB, and create CES_ICP_IDN, CES_ICP_IND, etc.
# Then I can do
# IND_FD_ICP <- t(CES_ICP_IND) %*% as.matrix(IND_FD_code[,2])
# to get FD in ICP classification.
source("rIPFP - Map_CES_COICOP.R")
# source("Init_consumption_vectors.R")  # Run once to generate and save those vectors
source("Load_init_data.R")
##########################################
### Read in function 'get_basic_price' ###
##########################################
source("rIPFP - Valuation.R")
# source("Load_init_data.R")
#################################################
### Read in function 'Bridging_uncertainty.R' ###
#################################################
# The uniform random draw routine based on a qual mapping
source("rIPFP - Bridging_uncertainty.R")
#################################################
### Read in function 'Bridging_uncertainty.R' ###
#################################################
source("rIPFP - Functions_for_intensity_analysis.R")
##############################################
###    Set up environment for RAS run      ###
##############################################
source("rIPFP - Bridge_RAS.R")
##############################################
###    Run analysis etc.!     ###
##############################################
# Analysis_for_paper.R is the main file for analysis
ICP_food_idx <- 1:45
ICP_hhold_idx <- c(56:84, 138:151)  # Household goods/services
ICP_svc_idx <- 85:137   # Health, Transport, Communication, Recreation
ICP_fuel_idx <-152:164
ICP_all_idx <- 1:164
# Total energy/year (EJ/year) - Good to be based on household consumption (ICP)
tot.clothing.BRA <- rowSums(BRA.tfei.icp[, idx.clothing.icp] %*% diag(BRA_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_BRA
tot.clothing.IND <- rowSums(IND.tfei.icp[, idx.clothing.icp] %*% diag(IND_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_IND
tot.clothing.ZAF <- rowSums(ZAF.tfei.icp[, idx.clothing.icp] %*% diag(ZAF_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_ZAF
tot.footwear.BRA <- (BRA.tfei.icp[, idx.footwear.icp] * BRA_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_BRA
tot.footwear.IND <- (IND.tfei.icp[, idx.footwear.icp] * IND_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_IND
tot.footwear.ZAF <- (ZAF.tfei.icp[, idx.footwear.icp] * ZAF_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_ZAF
tot.clothing.elec.BRA <- rowSums(BRA.tfei.icp.elec[, idx.clothing.icp] %*% diag(BRA_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_BRA
tot.clothing.elec.IND <- rowSums(IND.tfei.icp.elec[, idx.clothing.icp] %*% diag(IND_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_IND
tot.clothing.elec.ZAF <- rowSums(ZAF.tfei.icp.elec[, idx.clothing.icp] %*% diag(ZAF_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_ZAF
tot.footwear.elec.BRA <- (BRA.tfei.icp.elec[, idx.footwear.icp] * BRA_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_BRA
tot.footwear.elec.IND <- (IND.tfei.icp.elec[, idx.footwear.icp] * IND_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_IND
tot.footwear.elec.ZAF <- (ZAF.tfei.icp.elec[, idx.footwear.icp] * ZAF_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_ZAF
tot.clothing.non.elec.BRA <- rowSums(BRA.tfei.icp.non.elec[, idx.clothing.icp] %*% diag(BRA_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_BRA
tot.clothing.non.elec.IND <- rowSums(IND.tfei.icp.non.elec[, idx.clothing.icp] %*% diag(IND_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_IND
tot.clothing.non.elec.ZAF <- rowSums(ZAF.tfei.icp.non.elec[, idx.clothing.icp] %*% diag(ZAF_FD_ICP_usd2007[idx.clothing.icp, 1])) / 1e6 / scaler_ZAF
tot.footwear.non.elec.BRA <- (BRA.tfei.icp.non.elec[, idx.footwear.icp] * BRA_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_BRA
tot.footwear.non.elec.IND <- (IND.tfei.icp.non.elec[, idx.footwear.icp] * IND_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_IND
tot.footwear.non.elec.ZAF <- (ZAF.tfei.icp.non.elec[, idx.footwear.icp] * ZAF_FD_ICP_usd2007[idx.footwear.icp, 1]) / 1e6 / scaler_ZAF
# # Approach 2. Based on TPEI (.use) and individual hh expenditure (GJ/cap) - Better! But not used for simple integration
# # Apply both FC_ICP: Original and adjusted
# # Take the min and max from the two results for the DLE comparison
# load("./Saved tables/BRA_intensities_val_BRA.use.Rda") #BRA_intensity.use
# load("./Saved tables/BRA_FD_ICP_HH_adj_BR.Rda") #BRA_FD_ICP_HH_adj_BR
# load("./Saved tables/BRA_FD_harmonized.Rda") #BRA_FD_ICP_AllHH
# list[all_HH_c_BR, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'BRA', BRA_FD_ICP_HH_adj_BR, BRA_intensity.use) # more reliable than IND_intensity
# list[all_HH_c_BR, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'BRA', BRA_FD_ICP_HH_adj_BR, BRA.tfei.icp) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_BR) * as.numeric(BRA_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
# list[all_HH_c_BR, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'BRA', BRA_FD_ICP_AllHH, BRA_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_BR) * as.numeric(BRA_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
#
# load("./Saved tables/IND_intensities.use.Rda")
# load("./Saved tables/IND_FD_ICP_HH_adj.Rda")
# load("./Saved tables/IND_FD_harmonized.Rda") #IND_FD_ICP_AllHH
# list[all_HH_c_IN, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'IND', IND_FD_ICP_HH_adj, IND_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_IN) * as.numeric(IND_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
# list[all_HH_c_IN, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'IND', IND_FD_ICP_AllHH, IND_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_IN) * as.numeric(IND_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
#
# load("./Saved tables/ZAF_intensities.use.Rda")
# load("./Saved tables/ZAF_FD_ICP_HH_adj.Rda")
# load("./Saved tables/ZAF_FD_harmonized.Rda") #ZAF_FD_ICP_AllHH
# list[all_HH_c_ZA, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'ZAF', ZAF_FD_ICP_HH_adj, ZAF_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_ZA) * as.numeric(ZAF_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
# list[all_HH_c_ZA, sd_hs] <- GetHHSectoralEnergyPerCap(idx.clothing.icp,'ZAF', ZAF_FD_ICP_AllHH, ZAF_intensity.use) # more reliable than IND_intensity
# (SummarizeGJPerCap(all_HH_c_ZA) * as.numeric(ZAF_pop_2007)) %>% mutate(min=u-2*sd, max=u+2*sd)
#
# rm(all_HH_c_BR, all_HH_c_IN, all_HH_c_ZA)
# gc()
### 2. Deriving DLE threshold [kg/cap] for Clothing (and average too)
# Derive from India data and apply the same $/kg (IND) to get kg/cap in BRA and ZAF
datapath <- "C:/Users/min/IIASA/DLE - Documents/WS3 - Documents/Trajectories/Clothing/"
weight.clothing <- read_xlsx(paste0(datapath, "Weights-IND.xlsx"), range="A1:J31") %>% select(CODE, `g/each - MIN`, `g/each - MAX`) %>%
rename(weight.min=`g/each - MIN`, weight.max=`g/each - MAX`, code=CODE)
### India
# No quantity for some items (code=372, 356, 357, 368, 375) -> Assume same avg price as 'shirts, T-shirts' (for decile1) (code=363)
price.shirt <- as.numeric(IND_clothing %>% filter(code==363) %>% mutate(price=val_tot/qty_tot) %>%
left_join(IND_HH,  by = c("id" = "hhid")) %>% filter(decile=="decile1") %>%
summarise(price.shirt=weighted.mean(price, weight, na.rm=T)))
# Get total weight by hh in gram (and val_tot too)
clothing.all <- IND_clothing %>% inner_join(weight.clothing) %>%
mutate_cond(code %in% c(372, 356, 357, 368, 375), qty_tot=val_tot/price.shirt) %>% # fill in qty for no-price items
mutate(weight.tot=qty_tot*weight.min, weight.tot.max=qty_tot*weight.max) %>%
mutate_cond(code==374, weight.tot=qty_tot) %>% # knitting wool
group_by(id) %>% summarise(val_tot=sum(val_tot, na.rm=TRUE), weight.tot=sum(weight.tot, na.rm=TRUE), weight.tot.max=sum(weight.tot.max, na.rm=TRUE)) %>%
left_join(IND_HH, by = c("id" = "hhid"))
# Get total weight by hh in gram (and val_tot too)
footwear.all <- IND_footwear %>% inner_join(weight.clothing) %>%
mutate(weight.tot=qty_tot*weight.min, weight.tot.max=qty_tot*weight.max) %>%
group_by(id) %>% summarise(val_tot=sum(val_tot, na.rm=TRUE), weight.tot=sum(weight.tot, na.rm=TRUE), weight.tot.max=sum(weight.tot.max, na.rm=TRUE)) %>%
left_join(IND_HH, by = c("id" = "hhid"))
library(readr)
hdd.path <- "C:/Users/min/IIASA/DLE - Documents/WS2 - Documents/Analysis/Climate impacts and space conditioning/Data/output_by_state_BRAINDZAF/"
svy = "IND1"
IND_HH <- selectDBdata(ID, WEIGHT, CONSUMPTION, HH_SIZE, EXPENDITURE, REGION, tables=c(paste0(svy, '_HH'))) %>%
mutate_cond(region=="Orissa", region="Odisha")
# There were duplicate rows for Tamil Nadu, which had to be removed from the CSV files directly.
hdd.IND <-
# read_csv(paste0(hdd.path, "DoT_HDD_tas_18.3India.csv")) %>%
read_csv(paste0(hdd.path, "DoT_HDD_tas_30.0India.csv")) %>%
# read_csv(paste0(hdd.path, "DoT_HDD_tas_18India.csv")) %>%
filter(var=="HDDsum" & stat=="PopWeightAv") %>%
select(-index, -var, -stat, -State) %>%
rename(region=reg, HDD=value) %>%
mutate_cond(region=="NCT of Delhi", region="Delhi")
cdd.IND <- read_csv(paste0(hdd.path, "DoT_CDD_tas_18.3India.csv")) %>% filter(var=="CDDsum" & stat=="PopWeightAv") %>%
select(-index, -var, -stat, -State) %>%
rename(region=reg, CDD=value) %>%
mutate_cond(region=="NCT of Delhi", region="Delhi")
IND_HH <- IND_HH  %>% left_join(hdd.IND) %>%
# left_join(hdd.IND.18) %>%
left_join(cdd.IND)
avg.HDD.IND <- weighted.mean(IND_HH$HDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
# avg.HDD.18.IND <- weighted.mean(IND_HH$HDD.18, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE) # Weighted national average
avg.CDD.IND <- weighted.mean(IND_HH$CDD, w=IND_HH$weight*IND_HH$hh_size, na.rm=TRUE)
IND_HH.CDDHDD <- IND_HH %>%
mutate_cond(is.nan(HDD), HDD=avg.HDD.IND) %>%
# mutate_cond(is.nan(HDD.18), HDD.18=avg.HDD.18.IND) %>%
mutate_cond(is.nan(CDD), CDD=avg.CDD.IND) %>% select(id, region, HDD, CDD) #, HDD.18)
clothing.HDD <- clothing.all %>% full_join(footwear.all %>% select(id, weight.tot.f = weight.tot)) %>%
left_join(IND_HH.CDDHDD) %>%
mutate_at(vars(weight.tot, income), funs(pcap=./hh_size)) %>% mutate(HDD2 = HDD^2)
# # Eyeballing data
# ggplot(clothing.HDD, aes(x=HDD, y=weight.tot)) +
#   geom_point(aes(colour = decile))
# ggplot(clothing.HDD, aes(x=HDD.18, y=weight.tot)) +
#   geom_point(aes(colour = decile))
# ggplot(clothing.HDD, aes(x=HDD, y=weight.tot.f)) +
#   geom_point(aes(colour = decile))
# Detected evident outliers. Need to remove them
outliers <- clothing.HDD %>% filter(weight.tot > 100000  | weight.tot.f > 50000) %>% select(id)
outlier_consumption <- IND_clothing %>% right_join(outliers)
clothing.HDD <- clothing.HDD %>% filter(!(id %in% outliers$id))
# Clothing kg model
install_github("dgrtwo/broom")
library(broom)
lm.clothing <- lm(weight.tot ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
# lm.clothing <- lm(weight.tot ~ consumption + HDD + hh_size, clothing.HDD)
# lm.clothing.18 <- lm(weight.tot ~ expenditure + HDD.18 + hh_size, clothing.HDD, weights = weight)
lm.footwear <- lm(weight.tot.f ~ expenditure + HDD + hh_size, clothing.HDD, weights = weight)
summary(lm.clothing)
# summary(lm.clothing.18)
summary(lm.footwear)
tidy.clothing <-tidy(lm.clothing)
tidy.clothing
write.table(tidy.clothing, "clipboard", sep="\t", row.names = FALSE, col.names = TRUE)
clothing.region.income <- clothing.HDD %>% group_by(region, decile) %>%
summarise(weight.clothing = weighted.mean(weight.tot, w=weight), HDD = first(HDD), HDD.18 = first(HDD.18), weight=sum(weight))
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing)) +
geom_point(aes(group = decile, colour=decile))
clothing.region.income <- clothing.HDD %>% group_by(region, decile) %>%
summarise(weight.clothing = weighted.mean(weight.tot, w=weight), HDD = first(HDD),
# HDD.18 = first(HDD.18),
weight=sum(weight))
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing)) +
geom_point(aes(group = decile, colour=decile))
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 12) + labs(x="HDD.30")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 12) + labs(x="HDD.30", y="Household clothing consumption (kg)")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 12) + labs(x="HDD.30", y="Household clothing consumption (kg)", colour="Consumption decile")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)", colour="Consumption decile")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population") +
theme(legend.text = 14)
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight*hh_size, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population") +
theme(legend.text = 14)
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight*hh_size, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
head(clothing.region.income)
clothing.region.income <- clothing.HDD %>% group_by(region, decile) %>%
summarise(weight.clothing = weighted.mean(weight.tot, w=weight), HDD = first(HDD),
# HDD.18 = first(HDD.18),
weight=sum(weight*hh_size))
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=weight*hh_size, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
clothing.region.income <- clothing.HDD %>% group_by(region, decile) %>%
summarise(weight.clothing = weighted.mean(weight.tot, w=weight), HDD = first(HDD),
# HDD.18 = first(HDD.18),
pop=sum(weight*hh_size))
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=pop, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=pop, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15) + labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population") +
scale_size_manual(labels = c("10 mil", "20 mil"))
?scale_size_area
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=pop, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15, labels = c("10 mil", "20 mil")) +
labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
ggplot(clothing.region.income, aes(x=HDD, y=weight.clothing/1000, size=pop, group = decile, colour=decile)) +
stat_sum() + scale_size_area(max_size = 15, breaks=c(5e6, 1e7, 2e7), labels = c("5 mil" ,"10 mil", "20 mil")) +
labs(x="HDD.30", y="Household clothing consumption (kg)",
colour="Consumption decile", size="Population")
